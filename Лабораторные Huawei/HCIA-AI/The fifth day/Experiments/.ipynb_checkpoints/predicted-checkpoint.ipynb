{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D, Activation, Flatten, Dropout\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, weight, depth = 96, 96, 3\n",
    "classes = 5\n",
    "chanDim = -1\n",
    "input_shape = (height, weight, depth)\n",
    "epochs = 100\n",
    "lr = 1e-3\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "dataset = 'flower_photos'\n",
    "\n",
    "imagePaths = sorted(list(paths.list_images(dataset)))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flower_photos\\\\tulips\\\\2785458179_9130812eef_m.jpg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagePaths[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (input_shape[0], input_shape[1]))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "    \n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize images data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 792.72MB\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data, dtype='float') / 255.0\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] data matrix: {:.2f}MB\".format(data.nbytes / (1024 * 1000.0)))\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.2,\n",
    "                         zoom_range=0.2, horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(decay=lr/epochs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 91 steps, validate on 734 samples\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 62s 686ms/step - loss: 1.9324 - accuracy: 0.4346 - val_loss: 2.9727 - val_accuracy: 0.2575\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 61s 667ms/step - loss: 1.3887 - accuracy: 0.5234 - val_loss: 3.8593 - val_accuracy: 0.2575\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 61s 669ms/step - loss: 1.2593 - accuracy: 0.5517 - val_loss: 2.7357 - val_accuracy: 0.2984\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 61s 669ms/step - loss: 1.1734 - accuracy: 0.5885 - val_loss: 2.4710 - val_accuracy: 0.3569\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 62s 679ms/step - loss: 1.0374 - accuracy: 0.6147 - val_loss: 1.4743 - val_accuracy: 0.5041\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 61s 672ms/step - loss: 0.9962 - accuracy: 0.6484 - val_loss: 1.1355 - val_accuracy: 0.6035\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 62s 686ms/step - loss: 0.9077 - accuracy: 0.6625 - val_loss: 1.0255 - val_accuracy: 0.6403\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 61s 676ms/step - loss: 0.8868 - accuracy: 0.6715 - val_loss: 1.0215 - val_accuracy: 0.6730\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 61s 669ms/step - loss: 0.8613 - accuracy: 0.6815 - val_loss: 0.9367 - val_accuracy: 0.6485\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 61s 675ms/step - loss: 0.7955 - accuracy: 0.7004 - val_loss: 1.0310 - val_accuracy: 0.6812\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 61s 670ms/step - loss: 0.7319 - accuracy: 0.7204 - val_loss: 0.8251 - val_accuracy: 0.7030\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 61s 669ms/step - loss: 0.7382 - accuracy: 0.7176 - val_loss: 0.7569 - val_accuracy: 0.7384\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 61s 674ms/step - loss: 0.7169 - accuracy: 0.7287 - val_loss: 0.7045 - val_accuracy: 0.7493\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 61s 669ms/step - loss: 0.7103 - accuracy: 0.7328 - val_loss: 0.7390 - val_accuracy: 0.7452\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 61s 669ms/step - loss: 0.6757 - accuracy: 0.7421 - val_loss: 0.7777 - val_accuracy: 0.7180\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 61s 668ms/step - loss: 0.6425 - accuracy: 0.7500 - val_loss: 0.7285 - val_accuracy: 0.7711\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 61s 669ms/step - loss: 0.6528 - accuracy: 0.7521 - val_loss: 1.1106 - val_accuracy: 0.6676\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 61s 675ms/step - loss: 0.6543 - accuracy: 0.7514 - val_loss: 0.7305 - val_accuracy: 0.7384\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 61s 672ms/step - loss: 0.6344 - accuracy: 0.7675 - val_loss: 0.8200 - val_accuracy: 0.7561\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 61s 669ms/step - loss: 0.5943 - accuracy: 0.7758 - val_loss: 0.7659 - val_accuracy: 0.7330\n",
      "Epoch 21/100\n",
      "91/91 [==============================] - 61s 670ms/step - loss: 0.5906 - accuracy: 0.7772 - val_loss: 0.7133 - val_accuracy: 0.7657\n",
      "Epoch 22/100\n",
      "91/91 [==============================] - 61s 670ms/step - loss: 0.5209 - accuracy: 0.8103 - val_loss: 0.6560 - val_accuracy: 0.7602\n",
      "Epoch 23/100\n",
      "91/91 [==============================] - 61s 672ms/step - loss: 0.5513 - accuracy: 0.7906 - val_loss: 1.1113 - val_accuracy: 0.6635\n",
      "Epoch 24/100\n",
      "91/91 [==============================] - 61s 671ms/step - loss: 0.5715 - accuracy: 0.7882 - val_loss: 0.9653 - val_accuracy: 0.7125\n",
      "Epoch 25/100\n",
      "91/91 [==============================] - 61s 673ms/step - loss: 0.5196 - accuracy: 0.7996 - val_loss: 0.9304 - val_accuracy: 0.7248\n",
      "Epoch 26/100\n",
      "91/91 [==============================] - 61s 669ms/step - loss: 0.5070 - accuracy: 0.8123 - val_loss: 0.7548 - val_accuracy: 0.7275\n",
      "Epoch 27/100\n",
      "91/91 [==============================] - 62s 680ms/step - loss: 0.5320 - accuracy: 0.7999 - val_loss: 0.9766 - val_accuracy: 0.6676\n",
      "Epoch 28/100\n",
      "91/91 [==============================] - 61s 668ms/step - loss: 0.5539 - accuracy: 0.7982 - val_loss: 0.8595 - val_accuracy: 0.7330\n",
      "Epoch 29/100\n",
      "91/91 [==============================] - 61s 670ms/step - loss: 0.5241 - accuracy: 0.8041 - val_loss: 0.7471 - val_accuracy: 0.7629\n",
      "Epoch 30/100\n",
      "91/91 [==============================] - 61s 670ms/step - loss: 0.4747 - accuracy: 0.8192 - val_loss: 0.6142 - val_accuracy: 0.8025\n",
      "Epoch 31/100\n",
      "91/91 [==============================] - 58s 643ms/step - loss: 0.4451 - accuracy: 0.8368 - val_loss: 0.7767 - val_accuracy: 0.7398\n",
      "Epoch 32/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.4505 - accuracy: 0.8320 - val_loss: 0.6760 - val_accuracy: 0.7916\n",
      "Epoch 33/100\n",
      "91/91 [==============================] - 59s 644ms/step - loss: 0.4243 - accuracy: 0.8416 - val_loss: 0.6724 - val_accuracy: 0.7888\n",
      "Epoch 34/100\n",
      "91/91 [==============================] - 59s 644ms/step - loss: 0.4249 - accuracy: 0.8399 - val_loss: 0.6903 - val_accuracy: 0.7698\n",
      "Epoch 35/100\n",
      "91/91 [==============================] - 61s 675ms/step - loss: 0.4251 - accuracy: 0.8340 - val_loss: 0.5941 - val_accuracy: 0.7943\n",
      "Epoch 36/100\n",
      "91/91 [==============================] - 61s 669ms/step - loss: 0.3671 - accuracy: 0.8616 - val_loss: 0.9949 - val_accuracy: 0.7289\n",
      "Epoch 37/100\n",
      "91/91 [==============================] - 61s 669ms/step - loss: 0.4011 - accuracy: 0.8485 - val_loss: 0.5673 - val_accuracy: 0.7970\n",
      "Epoch 38/100\n",
      "91/91 [==============================] - 60s 665ms/step - loss: 0.3614 - accuracy: 0.8685 - val_loss: 0.7176 - val_accuracy: 0.7888\n",
      "Epoch 39/100\n",
      "91/91 [==============================] - 59s 646ms/step - loss: 0.3630 - accuracy: 0.8633 - val_loss: 1.0769 - val_accuracy: 0.7098\n",
      "Epoch 40/100\n",
      "91/91 [==============================] - 58s 643ms/step - loss: 0.4130 - accuracy: 0.8519 - val_loss: 1.1454 - val_accuracy: 0.6894\n",
      "Epoch 41/100\n",
      "91/91 [==============================] - 59s 644ms/step - loss: 0.3855 - accuracy: 0.8595 - val_loss: 0.9963 - val_accuracy: 0.7016\n",
      "Epoch 42/100\n",
      "91/91 [==============================] - 59s 645ms/step - loss: 0.3667 - accuracy: 0.8664 - val_loss: 0.5975 - val_accuracy: 0.8161\n",
      "Epoch 43/100\n",
      "91/91 [==============================] - 58s 643ms/step - loss: 0.3857 - accuracy: 0.8619 - val_loss: 1.4294 - val_accuracy: 0.6253\n",
      "Epoch 44/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.4006 - accuracy: 0.8523 - val_loss: 0.7347 - val_accuracy: 0.7684\n",
      "Epoch 45/100\n",
      "91/91 [==============================] - 58s 643ms/step - loss: 0.3263 - accuracy: 0.8822 - val_loss: 0.6945 - val_accuracy: 0.7956\n",
      "Epoch 46/100\n",
      "91/91 [==============================] - 59s 644ms/step - loss: 0.3252 - accuracy: 0.8805 - val_loss: 1.1055 - val_accuracy: 0.7166\n",
      "Epoch 47/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.2871 - accuracy: 0.8933 - val_loss: 0.7006 - val_accuracy: 0.7929\n",
      "Epoch 48/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.3092 - accuracy: 0.8895 - val_loss: 0.9088 - val_accuracy: 0.7234\n",
      "Epoch 49/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.3949 - accuracy: 0.8616 - val_loss: 0.6785 - val_accuracy: 0.8093\n",
      "Epoch 50/100\n",
      "91/91 [==============================] - 59s 644ms/step - loss: 0.3030 - accuracy: 0.8846 - val_loss: 0.7186 - val_accuracy: 0.7875\n",
      "Epoch 51/100\n",
      "91/91 [==============================] - 59s 645ms/step - loss: 0.3117 - accuracy: 0.8846 - val_loss: 0.8530 - val_accuracy: 0.7575\n",
      "Epoch 52/100\n",
      "91/91 [==============================] - 59s 645ms/step - loss: 0.3439 - accuracy: 0.8757 - val_loss: 1.2519 - val_accuracy: 0.7030\n",
      "Epoch 53/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.2682 - accuracy: 0.8988 - val_loss: 0.6234 - val_accuracy: 0.8188\n",
      "Epoch 54/100\n",
      "91/91 [==============================] - 59s 644ms/step - loss: 0.2921 - accuracy: 0.8946 - val_loss: 0.9765 - val_accuracy: 0.7520\n",
      "Epoch 55/100\n",
      "91/91 [==============================] - 59s 647ms/step - loss: 0.2929 - accuracy: 0.8887 - val_loss: 1.1779 - val_accuracy: 0.7125\n",
      "Epoch 56/100\n",
      "91/91 [==============================] - 59s 645ms/step - loss: 0.3050 - accuracy: 0.8898 - val_loss: 0.6779 - val_accuracy: 0.8188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.2505 - accuracy: 0.9081 - val_loss: 0.6919 - val_accuracy: 0.8106\n",
      "Epoch 58/100\n",
      "91/91 [==============================] - 59s 645ms/step - loss: 0.3110 - accuracy: 0.8788 - val_loss: 0.9080 - val_accuracy: 0.7616\n",
      "Epoch 59/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.2779 - accuracy: 0.8953 - val_loss: 0.7540 - val_accuracy: 0.8065\n",
      "Epoch 60/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.2250 - accuracy: 0.9122 - val_loss: 0.7188 - val_accuracy: 0.7916\n",
      "Epoch 61/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.2045 - accuracy: 0.9205 - val_loss: 0.6863 - val_accuracy: 0.8025\n",
      "Epoch 62/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.2325 - accuracy: 0.9108 - val_loss: 0.7206 - val_accuracy: 0.8106\n",
      "Epoch 63/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.2015 - accuracy: 0.9222 - val_loss: 0.9944 - val_accuracy: 0.7602\n",
      "Epoch 64/100\n",
      "91/91 [==============================] - 58s 643ms/step - loss: 0.2215 - accuracy: 0.9184 - val_loss: 0.7874 - val_accuracy: 0.7834\n",
      "Epoch 65/100\n",
      "91/91 [==============================] - 59s 644ms/step - loss: 0.2352 - accuracy: 0.9122 - val_loss: 1.1803 - val_accuracy: 0.7357\n",
      "Epoch 66/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.2368 - accuracy: 0.9149 - val_loss: 0.9132 - val_accuracy: 0.7711\n",
      "Epoch 67/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.2129 - accuracy: 0.9263 - val_loss: 0.8770 - val_accuracy: 0.7943\n",
      "Epoch 68/100\n",
      "91/91 [==============================] - 59s 644ms/step - loss: 0.1846 - accuracy: 0.9304 - val_loss: 0.7689 - val_accuracy: 0.8147\n",
      "Epoch 69/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.2025 - accuracy: 0.9253 - val_loss: 0.6997 - val_accuracy: 0.8147\n",
      "Epoch 70/100\n",
      "91/91 [==============================] - 59s 644ms/step - loss: 0.2317 - accuracy: 0.9201 - val_loss: 0.8006 - val_accuracy: 0.8188\n",
      "Epoch 71/100\n",
      "91/91 [==============================] - 58s 641ms/step - loss: 0.2022 - accuracy: 0.9253 - val_loss: 0.8503 - val_accuracy: 0.7916\n",
      "Epoch 72/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.1542 - accuracy: 0.9435 - val_loss: 0.7599 - val_accuracy: 0.8256\n",
      "Epoch 73/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.1895 - accuracy: 0.9301 - val_loss: 0.9561 - val_accuracy: 0.7807\n",
      "Epoch 74/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.1678 - accuracy: 0.9373 - val_loss: 0.6871 - val_accuracy: 0.8283\n",
      "Epoch 75/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.1828 - accuracy: 0.9339 - val_loss: 0.9615 - val_accuracy: 0.7725\n",
      "Epoch 76/100\n",
      "91/91 [==============================] - 58s 641ms/step - loss: 0.1643 - accuracy: 0.9397 - val_loss: 0.8285 - val_accuracy: 0.8202\n",
      "Epoch 77/100\n",
      "91/91 [==============================] - 58s 643ms/step - loss: 0.1485 - accuracy: 0.9439 - val_loss: 0.7479 - val_accuracy: 0.8297\n",
      "Epoch 78/100\n",
      "91/91 [==============================] - 58s 643ms/step - loss: 0.2037 - accuracy: 0.9301 - val_loss: 1.5811 - val_accuracy: 0.7207\n",
      "Epoch 79/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.1849 - accuracy: 0.9339 - val_loss: 1.0547 - val_accuracy: 0.8011\n",
      "Epoch 80/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.1598 - accuracy: 0.9425 - val_loss: 0.6909 - val_accuracy: 0.8365\n",
      "Epoch 81/100\n",
      "91/91 [==============================] - 58s 643ms/step - loss: 0.1358 - accuracy: 0.9528 - val_loss: 0.6682 - val_accuracy: 0.8351\n",
      "Epoch 82/100\n",
      "91/91 [==============================] - 58s 643ms/step - loss: 0.1654 - accuracy: 0.9394 - val_loss: 0.8297 - val_accuracy: 0.7875\n",
      "Epoch 83/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.1692 - accuracy: 0.9401 - val_loss: 0.9780 - val_accuracy: 0.8120\n",
      "Epoch 84/100\n",
      "91/91 [==============================] - 58s 643ms/step - loss: 0.1333 - accuracy: 0.9494 - val_loss: 1.2300 - val_accuracy: 0.7902\n",
      "Epoch 85/100\n",
      "91/91 [==============================] - 59s 645ms/step - loss: 0.1534 - accuracy: 0.9425 - val_loss: 0.7893 - val_accuracy: 0.8324\n",
      "Epoch 86/100\n",
      "91/91 [==============================] - 59s 645ms/step - loss: 0.1480 - accuracy: 0.9452 - val_loss: 0.7822 - val_accuracy: 0.8311\n",
      "Epoch 87/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.2119 - accuracy: 0.9225 - val_loss: 1.1220 - val_accuracy: 0.7834\n",
      "Epoch 88/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.2038 - accuracy: 0.9353 - val_loss: 0.9592 - val_accuracy: 0.7984\n",
      "Epoch 89/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.1279 - accuracy: 0.9514 - val_loss: 1.0176 - val_accuracy: 0.7861\n",
      "Epoch 90/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.1078 - accuracy: 0.9618 - val_loss: 0.8096 - val_accuracy: 0.8229\n",
      "Epoch 91/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.1805 - accuracy: 0.9356 - val_loss: 0.9504 - val_accuracy: 0.7984\n",
      "Epoch 92/100\n",
      "91/91 [==============================] - 58s 643ms/step - loss: 0.1571 - accuracy: 0.9404 - val_loss: 0.6808 - val_accuracy: 0.8447\n",
      "Epoch 93/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.1329 - accuracy: 0.9521 - val_loss: 0.7577 - val_accuracy: 0.8270\n",
      "Epoch 94/100\n",
      "91/91 [==============================] - 58s 643ms/step - loss: 0.1355 - accuracy: 0.9521 - val_loss: 0.8472 - val_accuracy: 0.8106\n",
      "Epoch 95/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.1609 - accuracy: 0.9428 - val_loss: 0.9252 - val_accuracy: 0.8202\n",
      "Epoch 96/100\n",
      "91/91 [==============================] - 58s 643ms/step - loss: 0.1217 - accuracy: 0.9587 - val_loss: 0.8047 - val_accuracy: 0.8311\n",
      "Epoch 97/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.1217 - accuracy: 0.9556 - val_loss: 1.1508 - val_accuracy: 0.7670\n",
      "Epoch 98/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.1074 - accuracy: 0.9621 - val_loss: 0.9559 - val_accuracy: 0.8038\n",
      "Epoch 99/100\n",
      "91/91 [==============================] - 58s 642ms/step - loss: 0.1010 - accuracy: 0.9673 - val_loss: 0.7510 - val_accuracy: 0.8324\n",
      "Epoch 100/100\n",
      "91/91 [==============================] - 59s 643ms/step - loss: 0.1692 - accuracy: 0.9435 - val_loss: 0.9561 - val_accuracy: 0.8038\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(x=aug.flow(X_train, y_train, batch_size=BS),\n",
    "              validation_data=(X_test, y_test),\n",
    "              steps_per_epoch=len(X_train) // BS,\n",
    "              epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       daisy       0.78      0.81      0.80       106\n",
      "   dandelion       0.87      0.83      0.85       189\n",
      "       roses       0.77      0.64      0.70       135\n",
      "  sunflowers       0.79      0.92      0.85       146\n",
      "      tulips       0.78      0.80      0.79       158\n",
      "\n",
      "    accuracy                           0.80       734\n",
      "   macro avg       0.80      0.80      0.80       734\n",
      "weighted avg       0.80      0.80      0.80       734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(x=X_test, batch_size=32)\n",
    "print(classification_report(y_test.argmax(axis=1),predictions.argmax(axis=1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('flowers.model', save_format=\"h5\")\n",
    "\n",
    "f = open('lb.pickle', \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = epochs\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig('plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction's time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_images/daisys.jpg', 'test_images/dandelion.jpg', 'test_images/roses.jpg', 'test_images/sunflowers.jpg', 'test_images/tulips.jpg']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from imutils import paths\n",
    "import imutils\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "height, width = 96, 96\n",
    "\n",
    "testPaths = sorted(list(paths.list_images('test_images')))\n",
    "print(testPaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('flowers.model')\n",
    "lb = pickle.loads(open('lb.pickle', \"rb\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict daisys: Network's answer is daisy: 100.00%\n",
      "Predict dandelion: Network's answer is dandelion: 100.00%\n",
      "Predict roses: Network's answer is roses: 100.00%\n",
      "Predict sunflowers: Network's answer is sunflowers: 100.00%\n",
      "Predict tulips: Network's answer is tulips: 99.96%\n"
     ]
    }
   ],
   "source": [
    "for flower in testPaths:\n",
    "    image = cv2.imread(flower)\n",
    "    image = imutils.resize(image, width=600)\n",
    "    output = image.copy()\n",
    "    # Resize image to the model's size\n",
    "    image = cv2.resize(image, (height, width))\n",
    "    \n",
    "    # Normalize the same way\n",
    "    image = image.astype('float') / 255.0\n",
    "    \n",
    "    # Add the batch dimension\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    \n",
    "    # Make prediction on the image\n",
    "    preds = model.predict(image)\n",
    "    i = preds.argmax(axis=1)[0]\n",
    "    label = lb.classes_[i]\n",
    "    \n",
    "    # Draw the label predict\n",
    "    answer = \"{}: {:.2f}%\".format(label, preds[0][i] * 100)\n",
    "    true = flower.split(os.path.sep)[-1].split('.')[0]\n",
    "    \n",
    "    print(\"Predict {}: Network's answer is {}\".format(true, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
